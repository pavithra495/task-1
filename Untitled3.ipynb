{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXW5j41p9++pS7SkzHUDth"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLxqKd8vXd8C","executionInfo":{"status":"ok","timestamp":1749030988569,"user_tz":-330,"elapsed":15,"user":{"displayName":"pavithra Priya","userId":"05395592676300555983"}},"outputId":"71460932-30ee-4f14-849d-c8ae909c44f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated text (order 1): the ther ox ox overox.\n","Generated text (order 2): the lazy fox.\n","Generated text (order 3): to take arms and them\n"]}],"source":["import random\n","from collections import defaultdict\n","\n","class MarkovTextGenerator:\n","    def __init__(self, order):\n","        self.order = order\n","        self.markov_map = defaultdict(list)\n","\n","    def train(self, text):\n","        if not text:\n","            return\n","\n","        # Pad the text to handle the beginning\n","        text = \" \" * self.order + text\n","\n","        for i in range(len(text) - self.order):\n","            current_state = text[i : i + self.order]\n","            next_char = text[i + self.order]\n","            self.markov_map[current_state].append(next_char)\n","\n","    def generate(self, length=100, start_state=None):\n","        if not self.markov_map:\n","            return \"Model not trained.\"\n","\n","        if start_state is None:\n","            start_state = random.choice(list(self.markov_map.keys()))\n","        elif len(start_state) != self.order:\n","            return f\"Starting state must be of length {self.order}.\"\n","        elif start_state not in self.markov_map:\n","            return \"Starting state not found in the trained data.\"\n","\n","        generated_text = start_state\n","        current_state = start_state\n","\n","        for _ in range(length - self.order):\n","            possible_next = self.markov_map.get(current_state)\n","            if not possible_next:\n","                break  # Stop if no next character is found for the current state\n","\n","            next_char = random.choice(possible_next)\n","            generated_text += next_char\n","            current_state = generated_text[-self.order :]\n","\n","        return generated_text\n","\n","if __name__ == \"__main__\":\n","    # Example usage with character-level Markov chain of order 2\n","    text_corpus = \"the quick brown fox jumps over the lazy fox.\"\n","\n","    # Train the model with order 1 (predict next character based on the previous one)\n","    order_1_generator = MarkovTextGenerator(order=1)\n","    order_1_generator.train(text_corpus)\n","    generated_text_order_1 = order_1_generator.generate(length=50, start_state=\"t\")\n","    print(\"Generated text (order 1):\", generated_text_order_1)\n","\n","    # Train the model with order 2 (predict next character based on the previous two)\n","    order_2_generator = MarkovTextGenerator(order=2)\n","    order_2_generator.train(text_corpus)\n","    generated_text_order_2 = order_2_generator.generate(length=50, start_state=\"th\")\n","    print(\"Generated text (order 2):\", generated_text_order_2)\n","\n","    # Example with a different text and order 3\n","    long_text = \"to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles and by opposing end them\"\n","    order_3_generator = MarkovTextGenerator(order=3)\n","    order_3_generator.train(long_text)\n","    generated_text_order_3 = order_3_generator.generate(length=80, start_state=\"to \")\n","    print(\"Generated text (order 3):\", generated_text_order_3)"]}]}